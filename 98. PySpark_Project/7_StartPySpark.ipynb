{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec797012-25ae-40c6-b5e2-7d3ac7e48a8b",
   "metadata": {},
   "source": [
    "# Starting a PySpark Session\n",
    "\n",
    "- PySpark requires a SparkSession to interact with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d61ce6f-6ec4-4f66-bfc0-e1086bdabade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x1081d0810>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySparkLearning\").getOrCreate()\n",
    "\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb820c8a-1095-4862-92e5-afb90a9b59e1",
   "metadata": {},
   "source": [
    "# Loading a CSV File into a DataFrame\n",
    "\n",
    "- `header=True` means the first row contains column names\n",
    "- `inferSchema = True` allows Spark to detect data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf9b4f5-9e39-4e56-b7ae-8c2f54c6ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-----------+-----+------------+-------+---------+-----+------+------+-----------+-------+---------------+-------------------+-------------+---------------+-------------------+----------+-----------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|       City|State|LocationType|    Lat|     Long|Xaxis| Yaxis| Zaxis|WorldRegion|Country|   LocationText|           Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|            Notes|\n",
      "+------------+-------+-----------+-----------+-----+------------+-------+---------+-----+------+------+-----------+-------+---------------+-------------------+-------------+---------------+-------------------+----------+-----------------+\n",
      "|           1|  10001|   STANDARD|   New York|   NY|     PRIMARY|40.7128|  -74.006|  123|456.78|789.01|         NA|     US|   New York, NY| (40.7128,-74.0060)|        false|          50000|             211000|  50000000|       Urban area|\n",
      "|           2|  90001|   STANDARD|Los Angeles|   CA|     PRIMARY|34.0522|-118.2437|  124|457.79|790.02|         NA|     US|Los Angeles, CA|(34.0522,-118.2437)|        false|          60000|             380000|  75000000|   West Coast hub|\n",
      "|           3|  60601|   STANDARD|    Chicago|   IL|     PRIMARY|41.8781| -87.6298|  125| 458.8|791.03|         NA|     US|    Chicago, IL| (41.8781,-87.6298)|        false|          55000|             270000|  62000000|     Midwest city|\n",
      "|           4|  77001|   STANDARD|    Houston|   TX|     PRIMARY|29.7604| -95.3698|  126|459.81|792.04|         NA|     US|    Houston, TX| (29.7604,-95.3698)|        false|          53000|             300000|  69000000|   Energy capital|\n",
      "|           5|  85001|   STANDARD|    Phoenix|   AZ|     PRIMARY|33.4484| -112.074|  127|460.82|793.05|         NA|     US|    Phoenix, AZ|(33.4484,-112.0740)|        false|          51000|             220000|  58000000|Desert metropolis|\n",
      "+------------+-------+-----------+-----------+-----+------------+-------+---------+-----+------+------+-----------+-------+---------------+-------------------+-------------+---------------+-------------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = './resources/3_zipcodes.csv'\n",
    "spark = SparkSession.builder.appName(\"PySparkLearning\").getOrCreate()\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e93579-0db4-41fd-b05d-6eeb4a41de39",
   "metadata": {},
   "source": [
    "# Basic DataFrame Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee684e14-5f67-4d2f-90f3-ae345762b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: integer (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n",
      "+-----------+-----+\n",
      "|       City|State|\n",
      "+-----------+-----+\n",
      "|   New York|   NY|\n",
      "|Los Angeles|   CA|\n",
      "|    Chicago|   IL|\n",
      "|    Houston|   TX|\n",
      "|    Phoenix|   AZ|\n",
      "+-----------+-----+\n",
      "\n",
      "+------------+-------+-----------+-------+-----+------------+-------+--------+-----+-----+------+-----------+-------+------------+------------------+-------------+---------------+-------------------+----------+------------+\n",
      "|RecordNumber|Zipcode|ZipCodeType|   City|State|LocationType|    Lat|    Long|Xaxis|Yaxis| Zaxis|WorldRegion|Country|LocationText|          Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|       Notes|\n",
      "+------------+-------+-----------+-------+-----+------------+-------+--------+-----+-----+------+-----------+-------+------------+------------------+-------------+---------------+-------------------+----------+------------+\n",
      "|           3|  60601|   STANDARD|Chicago|   IL|     PRIMARY|41.8781|-87.6298|  125|458.8|791.03|         NA|     US| Chicago, IL|(41.8781,-87.6298)|        false|          55000|             270000|  62000000|Midwest city|\n",
      "+------------+-------+-----------+-------+-----+------------+-------+--------+-----+-----+------+-----------+-------+------------+------------------+-------------+---------------+-------------------+----------+------------+\n",
      "\n",
      "+-----------+-----+\n",
      "|       City|count|\n",
      "+-----------+-----+\n",
      "|    Phoenix|    1|\n",
      "|Los Angeles|    1|\n",
      "|    Chicago|    1|\n",
      "|    Houston|    1|\n",
      "|   New York|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySparkLearning\").getOrCreate()\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema() # Show Schema\n",
    "df.select(\"City\", \"State\").show(5) # Select column\n",
    "df.filter(df[\"City\"] == 'Chicago').show() # Applying filter\n",
    "df.groupBy(\"City\").count().show() # Group and count\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
