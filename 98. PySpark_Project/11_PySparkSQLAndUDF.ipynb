{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43fee51-aced-4397-b274-c4153190799e",
   "metadata": {},
   "source": [
    "# PySpark SQL and UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859b9e1-4e80-4821-8604-04fe119ccfb9",
   "metadata": {},
   "source": [
    "## Using SQL Queries in PySpark\n",
    "- you can run SQL queries directly on PySpark DataFrames.\n",
    "- helpful when you need to work with complex queries or when transitioning from SQL-based operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c758d867-18bb-4448-b155-290b202ba99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+------+\n",
      "|employee_id|     name|department|salary|\n",
      "+-----------+---------+----------+------+\n",
      "|          1|     John|        HR| 55000|\n",
      "|          2|     Jane|   Finance| 80000|\n",
      "|          3|    James|        HR| 60000|\n",
      "|          4|     Anna|   Finance| 90000|\n",
      "|          5|      Bob| Marketing| 75000|\n",
      "|          6|    Emily| Marketing| 82000|\n",
      "|          7|    David|        HR| 65000|\n",
      "|          8|   George|   Finance| 95000|\n",
      "|          9|   Olivia| Marketing| 68000|\n",
      "|         10|     Liam|        HR| 54000|\n",
      "|         11|   Sophia|   Finance| 85000|\n",
      "|         12|    Lucas| Marketing| 78000|\n",
      "|         13| Isabella|   Finance| 92000|\n",
      "|         14|    Mason|        HR| 63000|\n",
      "|         15|   Amelia| Marketing| 79000|\n",
      "|         16|    Ethan|        HR| 67000|\n",
      "|         17|  Abigail|   Finance| 87000|\n",
      "|         18|    Aiden|        HR| 56000|\n",
      "|         19|Charlotte| Marketing| 81000|\n",
      "|         20|     Jack|        HR| 69000|\n",
      "+-----------+---------+----------+------+\n",
      "\n",
      "+-----------+---------+----------+------+\n",
      "|employee_id|     name|department|salary|\n",
      "+-----------+---------+----------+------+\n",
      "|          1|     John|        HR| 55000|\n",
      "|          2|     Jane|   Finance| 80000|\n",
      "|          3|    James|        HR| 60000|\n",
      "|          4|     Anna|   Finance| 90000|\n",
      "|          5|      Bob| Marketing| 75000|\n",
      "|          6|    Emily| Marketing| 82000|\n",
      "|          7|    David|        HR| 65000|\n",
      "|          8|   George|   Finance| 95000|\n",
      "|          9|   Olivia| Marketing| 68000|\n",
      "|         10|     Liam|        HR| 54000|\n",
      "|         11|   Sophia|   Finance| 85000|\n",
      "|         12|    Lucas| Marketing| 78000|\n",
      "|         13| Isabella|   Finance| 92000|\n",
      "|         14|    Mason|        HR| 63000|\n",
      "|         15|   Amelia| Marketing| 79000|\n",
      "|         16|    Ethan|        HR| 67000|\n",
      "|         17|  Abigail|   Finance| 87000|\n",
      "|         18|    Aiden|        HR| 56000|\n",
      "|         19|Charlotte| Marketing| 81000|\n",
      "|         20|     Jack|        HR| 69000|\n",
      "+-----------+---------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TestSQL\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv('./resources/7_employee.csv', header=True, inferSchema=True)\n",
    "\n",
    "df.createOrReplaceTempView('employees')\n",
    "\n",
    "sql = spark.sql('select * from employees')\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834a108-493d-4680-b50e-ee969a930284",
   "metadata": {},
   "source": [
    "## Using UDFs (User-Defined Functions)\n",
    "- when PySpark's built-in functions aren't enough, you can write your own UDFs. UDFs allow you to apply custom Python functions to PySpark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98353c15-7fe6-424d-b12b-4fb0d64dd576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+------+------+\n",
      "|employee_id|     name|department|salary| bonus|\n",
      "+-----------+---------+----------+------+------+\n",
      "|          1|     John|        HR| 55000|5500.0|\n",
      "|          2|     Jane|   Finance| 80000|8000.0|\n",
      "|          3|    James|        HR| 60000|6000.0|\n",
      "|          4|     Anna|   Finance| 90000|9000.0|\n",
      "|          5|      Bob| Marketing| 75000|7500.0|\n",
      "|          6|    Emily| Marketing| 82000|8200.0|\n",
      "|          7|    David|        HR| 65000|6500.0|\n",
      "|          8|   George|   Finance| 95000|9500.0|\n",
      "|          9|   Olivia| Marketing| 68000|6800.0|\n",
      "|         10|     Liam|        HR| 54000|5400.0|\n",
      "|         11|   Sophia|   Finance| 85000|8500.0|\n",
      "|         12|    Lucas| Marketing| 78000|7800.0|\n",
      "|         13| Isabella|   Finance| 92000|9200.0|\n",
      "|         14|    Mason|        HR| 63000|6300.0|\n",
      "|         15|   Amelia| Marketing| 79000|7900.0|\n",
      "|         16|    Ethan|        HR| 67000|6700.0|\n",
      "|         17|  Abigail|   Finance| 87000|8700.0|\n",
      "|         18|    Aiden|        HR| 56000|5600.0|\n",
      "|         19|Charlotte| Marketing| 81000|8100.0|\n",
      "|         20|     Jack|        HR| 69000|6900.0|\n",
      "+-----------+---------+----------+------+------+\n",
      "\n",
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- bonus: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, FloatType\n",
    "\n",
    "# define simple UDF to convert salary to a bonus\n",
    "def calculate_bonus(salary):\n",
    "    return salary * 0.1\n",
    "\n",
    "# register udf; StringType() -> specifies the return type like: StringType(), FloatType(), DoubleType()\n",
    "bonus_udf = udf(calculate_bonus, FloatType())\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TestSQL\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv('./resources/7_employee.csv', header=True, inferSchema=True)\n",
    "\n",
    "df_with_bonus = df.withColumn('bonus', bonus_udf(df['salary']))\n",
    "df_with_bonus.show()\n",
    "df_with_bonus.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854720b7-79ce-4584-a8b2-742a0c4f4fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
